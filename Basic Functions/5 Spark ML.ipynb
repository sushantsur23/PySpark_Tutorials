{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"68a7b267-2a1f-4a62-b6fd-d6cbab3efd00","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">+-----+--------------------+--------------------+--------------------+--------------------+\n","label|            sentence|               words|         rawFeatures|            features|\n","+-----+--------------------+--------------------+--------------------+--------------------+\n","  0.0|Hi I heard about ...|[hi, i, heard, ab...|(20,[0,5,9,17],[1...|(20,[0,5,9,17],[0...|\n","  0.0|I wish Java could...|[i, wish, java, c...|(20,[2,7,9,13,15]...|(20,[2,7,9,13,15]...|\n","  1.0|Logistic regressi...|[logistic, regres...|(20,[4,6,13,15,18...|(20,[4,6,13,15,18...|\n","+-----+--------------------+--------------------+--------------------+--------------------+\n","\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">+-----+--------------------+--------------------+--------------------+--------------------+\n|label|            sentence|               words|         rawFeatures|            features|\n+-----+--------------------+--------------------+--------------------+--------------------+\n|  0.0|Hi I heard about ...|[hi, i, heard, ab...|(20,[0,5,9,17],[1...|(20,[0,5,9,17],[0...|\n|  0.0|I wish Java could...|[i, wish, java, c...|(20,[2,7,9,13,15]...|(20,[2,7,9,13,15]...|\n|  1.0|Logistic regressi...|[logistic, regres...|(20,[4,6,13,15,18...|(20,[4,6,13,15,18...|\n+-----+--------------------+--------------------+--------------------+--------------------+\n\n</div>","datasetInfos":[{"name":"sentenceData","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null,"typeStr":"pyspark.sql.dataframe.DataFrame"},{"name":"wordsData","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"},{"metadata":{},"name":"words","nullable":true,"type":{"containsNull":true,"elementType":"string","type":"array"}}],"type":"struct"},"tableIdentifier":null,"typeStr":"pyspark.sql.dataframe.DataFrame"},{"name":"featurizedData","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"},{"metadata":{},"name":"words","nullable":true,"type":{"containsNull":true,"elementType":"string","type":"array"}},{"metadata":{"ml_attr":{"num_attrs":20}},"name":"rawFeatures","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null,"typeStr":"pyspark.sql.dataframe.DataFrame"},{"name":"rescaledData","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"},{"metadata":{},"name":"words","nullable":true,"type":{"containsNull":true,"elementType":"string","type":"array"}},{"metadata":{"ml_attr":{"num_attrs":20}},"name":"rawFeatures","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}},{"metadata":{},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null,"typeStr":"pyspark.sql.dataframe.DataFrame"}],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["#Feature Extraction - TF IDF\n","from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n","\n","sentenceData = spark.createDataFrame([\n","    (0.0, \"Hi I heard about Spark\"),\n","    (0.0, \"I wish Java could use case classes\"),\n","    (1.0, \"Logistic regression models are neat\")\n","], [\"label\", \"sentence\"])\n","\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","wordsData = tokenizer.transform(sentenceData)\n","\n","\n","hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n","featurizedData = hashingTF.transform(wordsData)\n","\n","# alternatively, CountVectorizer can also be used to get term frequency vectors\n","\n","idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n","idfModel = idf.fit(featurizedData)\n","rescaledData = idfModel.transform(featurizedData)\n","\n","rescaledData.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"12f89ba6-a771-4fd4-b233-560d3ae31cc9","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">+-----------------------------------+------------------------------------------+------+\n","sentence                           |words                                     |tokens|\n","+-----------------------------------+------------------------------------------+------+\n","Hi I heard about Spark             |[hi, i, heard, about, spark]              |5     |\n","I wish Java could use case classes |[i, wish, java, could, use, case, classes]|7     |\n","Logistic,regression,models,are,neat|[logistic,regression,models,are,neat]     |1     |\n","+-----------------------------------+------------------------------------------+------+\n","\n","+-----------------------------------+------------------------------------------+------+\n","sentence                           |words                                     |tokens|\n","+-----------------------------------+------------------------------------------+------+\n","Hi I heard about Spark             |[hi, i, heard, about, spark]              |5     |\n","I wish Java could use case classes |[i, wish, java, could, use, case, classes]|7     |\n","Logistic,regression,models,are,neat|[logistic, regression, models, are, neat] |5     |\n","+-----------------------------------+------------------------------------------+------+\n","\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">+-----------------------------------+------------------------------------------+------+\n|sentence                           |words                                     |tokens|\n+-----------------------------------+------------------------------------------+------+\n|Hi I heard about Spark             |[hi, i, heard, about, spark]              |5     |\n|I wish Java could use case classes |[i, wish, java, could, use, case, classes]|7     |\n|Logistic,regression,models,are,neat|[logistic,regression,models,are,neat]     |1     |\n+-----------------------------------+------------------------------------------+------+\n\n+-----------------------------------+------------------------------------------+------+\n|sentence                           |words                                     |tokens|\n+-----------------------------------+------------------------------------------+------+\n|Hi I heard about Spark             |[hi, i, heard, about, spark]              |5     |\n|I wish Java could use case classes |[i, wish, java, could, use, case, classes]|7     |\n|Logistic,regression,models,are,neat|[logistic, regression, models, are, neat] |5     |\n+-----------------------------------+------------------------------------------+------+\n\n</div>","datasetInfos":[{"name":"sentenceDataFrame","schema":{"fields":[{"metadata":{},"name":"id","nullable":true,"type":"long"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null,"typeStr":"pyspark.sql.dataframe.DataFrame"},{"name":"tokenized","schema":{"fields":[{"metadata":{},"name":"id","nullable":true,"type":"long"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"},{"metadata":{},"name":"words","nullable":true,"type":{"containsNull":true,"elementType":"string","type":"array"}}],"type":"struct"},"tableIdentifier":null,"typeStr":"pyspark.sql.dataframe.DataFrame"},{"name":"regexTokenized","schema":{"fields":[{"metadata":{},"name":"id","nullable":true,"type":"long"},{"metadata":{},"name":"sentence","nullable":true,"type":"string"},{"metadata":{},"name":"words","nullable":true,"type":{"containsNull":true,"elementType":"string","type":"array"}}],"type":"struct"},"tableIdentifier":null,"typeStr":"pyspark.sql.dataframe.DataFrame"}],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["#Feature Transformation  - Tokenizer\n","\n","from pyspark.ml.feature import Tokenizer, RegexTokenizer\n","from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType\n","\n","sentenceDataFrame = spark.createDataFrame([\n","    (0, \"Hi I heard about Spark\"),\n","    (1, \"I wish Java could use case classes\"),\n","    (2, \"Logistic,regression,models,are,neat\")\n","], [\"id\", \"sentence\"])\n","\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","\n","regexTokenizer = RegexTokenizer(inputCol=\"sentence\", outputCol=\"words\", pattern=\"\\\\W\")\n","# alternatively, pattern=\"\\\\w+\", gaps(False)\n","\n","countTokens = udf(lambda words: len(words), IntegerType())\n","\n","tokenized = tokenizer.transform(sentenceDataFrame)\n","tokenized.select(\"sentence\", \"words\")\\\n","    .withColumn(\"tokens\", countTokens(col(\"words\"))).show(truncate=False)\n","\n","regexTokenized = regexTokenizer.transform(sentenceDataFrame)\n","regexTokenized.select(\"sentence\", \"words\") \\\n","    .withColumn(\"tokens\", countTokens(col(\"words\"))).show(truncate=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"149ec783-4bea-4fff-b3c2-b16598cc2dc7","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">+--------------------+-------------+\n","        userFeatures|     features|\n","+--------------------+-------------+\n","(3,[0,1],[-2.0,2.3])|(1,[0],[2.3])|\n","      [-2.0,2.3,0.0]|        [2.3]|\n","+--------------------+-------------+\n","\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">+--------------------+-------------+\n|        userFeatures|     features|\n+--------------------+-------------+\n|(3,[0,1],[-2.0,2.3])|(1,[0],[2.3])|\n|      [-2.0,2.3,0.0]|        [2.3]|\n+--------------------+-------------+\n\n</div>","datasetInfos":[{"name":"df","schema":{"fields":[{"metadata":{},"name":"userFeatures","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null,"typeStr":"pyspark.sql.dataframe.DataFrame"},{"name":"output","schema":{"fields":[{"metadata":{},"name":"userFeatures","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}},{"metadata":{"ml_attr":{"num_attrs":1}},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null,"typeStr":"pyspark.sql.dataframe.DataFrame"}],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["#Feature Selector - Vector Slicer\n","\n","from pyspark.ml.feature import VectorSlicer\n","from pyspark.ml.linalg import Vectors\n","from pyspark.sql.types import Row\n","\n","df = spark.createDataFrame([\n","    Row(userFeatures=Vectors.sparse(3, {0: -2.0, 1: 2.3})),\n","    Row(userFeatures=Vectors.dense([-2.0, 2.3, 0.0]))])\n","\n","slicer = VectorSlicer(inputCol=\"userFeatures\", outputCol=\"features\", indices=[1])\n","\n","output = slicer.transform(df)\n","\n","output.select(\"userFeatures\", \"features\").show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3da859aa-6606-4e2c-9ff3-9deb10155502","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">+--------------------+\n","            features|\n","+--------------------+\n","(4,[0,3],[1.0,-2.0])|\n","   [4.0,5.0,0.0,3.0]|\n","   [6.0,7.0,0.0,8.0]|\n"," (4,[0,3],[9.0,1.0])|\n","+--------------------+\n","\n","Pearson correlation matrix:\n","DenseMatrix([[1.        , 0.05564149,        nan, 0.40047142],\n","             [0.05564149, 1.        ,        nan, 0.91359586],\n","             [       nan,        nan, 1.        ,        nan],\n","             [0.40047142, 0.91359586,        nan, 1.        ]])\n","Spearman correlation matrix:\n","DenseMatrix([[1.        , 0.10540926,        nan, 0.4       ],\n","             [0.10540926, 1.        ,        nan, 0.9486833 ],\n","             [       nan,        nan, 1.        ,        nan],\n","             [0.4       , 0.9486833 ,        nan, 1.        ]])\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">+--------------------+\n|            features|\n+--------------------+\n|(4,[0,3],[1.0,-2.0])|\n|   [4.0,5.0,0.0,3.0]|\n|   [6.0,7.0,0.0,8.0]|\n| (4,[0,3],[9.0,1.0])|\n+--------------------+\n\nPearson correlation matrix:\nDenseMatrix([[1.        , 0.05564149,        nan, 0.40047142],\n             [0.05564149, 1.        ,        nan, 0.91359586],\n             [       nan,        nan, 1.        ,        nan],\n             [0.40047142, 0.91359586,        nan, 1.        ]])\nSpearman correlation matrix:\nDenseMatrix([[1.        , 0.10540926,        nan, 0.4       ],\n             [0.10540926, 1.        ,        nan, 0.9486833 ],\n             [       nan,        nan, 1.        ,        nan],\n             [0.4       , 0.9486833 ,        nan, 1.        ]])\n</div>","datasetInfos":[{"name":"df","schema":{"fields":[{"metadata":{},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null,"typeStr":"pyspark.sql.dataframe.DataFrame"}],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["#Corelation\n","from pyspark.ml.linalg import Vectors\n","from pyspark.ml.stat import Correlation\n","\n","data = [(Vectors.sparse(4, [(0, 1.0), (3, -2.0)]),),\n","        (Vectors.dense([4.0, 5.0, 0.0, 3.0]),),\n","        (Vectors.dense([6.0, 7.0, 0.0, 8.0]),),\n","        (Vectors.sparse(4, [(0, 9.0), (3, 1.0)]),)]\n","df = spark.createDataFrame(data, [\"features\"])\n","df.show()\n","\n","\n","r1 = Correlation.corr(df, \"features\").head()\n","print(\"Pearson correlation matrix:\\n\" + str(r1[0]))\n","\n","r2 = Correlation.corr(df, \"features\", \"spearman\").head()\n","print(\"Spearman correlation matrix:\\n\" + str(r2[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d12b17e6-a413-4c33-baa3-9c6f2fe21fe3","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">Coefficients: [0.0,0.32292516677405936,-0.3438548034562218,1.9156017023458414,0.05288058680386263,0.765962720459771,0.0,-0.15105392669186682,-0.21587930360904642,0.22025369188813426]\n","Intercept: 0.1598936844239736\n","numIterations: 7\n","objectiveHistory: [0.49999999999999994, 0.4967620357443381, 0.4936361664340463, 0.4936351537897608, 0.4936351214177871, 0.49363512062528014, 0.4936351206216114]\n","+--------------------+\n","           residuals|\n","+--------------------+\n","  -9.889232683103197|\n","  0.5533794340053554|\n","  -5.204019455758823|\n"," -20.566686715507508|\n","    -9.4497405180564|\n","  -6.909112502719486|\n","  -10.00431602969873|\n","   2.062397807050484|\n","  3.1117508432954772|\n"," -15.893608229419382|\n","  -5.036284254673026|\n","   6.483215876994333|\n","  12.429497299109002|\n","  -20.32003219007654|\n"," -2.0049838218725005|\n"," -17.867901734183793|\n","   7.646455887420495|\n"," -2.2653482182417406|\n","-0.10308920436195645|\n","  -1.380034070385301|\n","+--------------------+\n","only showing top 20 rows\n","\n","RMSE: 10.189077\n","r2: 0.022861\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">Coefficients: [0.0,0.32292516677405936,-0.3438548034562218,1.9156017023458414,0.05288058680386263,0.765962720459771,0.0,-0.15105392669186682,-0.21587930360904642,0.22025369188813426]\nIntercept: 0.1598936844239736\nnumIterations: 7\nobjectiveHistory: [0.49999999999999994, 0.4967620357443381, 0.4936361664340463, 0.4936351537897608, 0.4936351214177871, 0.49363512062528014, 0.4936351206216114]\n+--------------------+\n|           residuals|\n+--------------------+\n|  -9.889232683103197|\n|  0.5533794340053554|\n|  -5.204019455758823|\n| -20.566686715507508|\n|    -9.4497405180564|\n|  -6.909112502719486|\n|  -10.00431602969873|\n|   2.062397807050484|\n|  3.1117508432954772|\n| -15.893608229419382|\n|  -5.036284254673026|\n|   6.483215876994333|\n|  12.429497299109002|\n|  -20.32003219007654|\n| -2.0049838218725005|\n| -17.867901734183793|\n|   7.646455887420495|\n| -2.2653482182417406|\n|-0.10308920436195645|\n|  -1.380034070385301|\n+--------------------+\nonly showing top 20 rows\n\nRMSE: 10.189077\nr2: 0.022861\n</div>","datasetInfos":[{"name":"training","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{"numFeatures":10},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null,"typeStr":"pyspark.sql.dataframe.DataFrame"}],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["#Linear Regression\n","\n","from pyspark.ml.regression import LinearRegression\n","\n","# Load training data\n","training = spark.read.format(\"libsvm\")\\\n","    .load(\"/FileStore/tables/data_mllib_sample_linear_regression_data.txt\")\n","\n","lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n","\n","# Fit the model\n","lrModel = lr.fit(training)\n","\n","# Print the coefficients and intercept for linear regression\n","print(\"Coefficients: %s\" % str(lrModel.coefficients))\n","print(\"Intercept: %s\" % str(lrModel.intercept))\n","\n","# Summarize the model over the training set and print out some metrics\n","trainingSummary = lrModel.summary\n","print(\"numIterations: %d\" % trainingSummary.totalIterations)\n","print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n","trainingSummary.residuals.show()\n","print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n","print(\"r2: %f\" % trainingSummary.r2)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d56ca426-f6bc-4e19-b13a-8d80064b839c","showTitle":false,"title":""}},"outputs":[],"source":[]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"5 Spark ML","notebookOrigID":4462370009969870,"widgets":{}},"kernelspec":{"display_name":"Python 3.9.7 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.7"},"vscode":{"interpreter":{"hash":"63cd14186f4f9ee1f3a96aa244a291192614759cb70b0eeee1e1147c30b53c71"}}},"nbformat":4,"nbformat_minor":0}
